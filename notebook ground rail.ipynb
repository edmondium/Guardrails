{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b362f0",
   "metadata": {},
   "source": [
    "# Grounding: Fact Checking and Hallucination\n",
    "\n",
    "In this example, we cover some of the different strategies we can use to ensure that our bot's responses are grounded in reality.\n",
    "\n",
    "In particular, we'll look at two approaches:\n",
    "\n",
    "1. **Fact Checking** - Comparing bot responses against text retrieved from a knowledge base to see if the responses are accurate\n",
    "2. **Hallucination Detection** - \"Self-checking\" bot responses by generating multiple responses and testing their internal consistency\n",
    "\n",
    "This example includes the following items\n",
    "\n",
    "- `kb/` - A folder containing our knowledge base to retrieve context from and fact check against. In this case, we include the March 2023 US Jobs report in `kb/report.md`.\n",
    "- `llm_config.yaml` - A config file defining the Large Language Model used.\n",
    "- `general.co` - A colang file with some generic examples of colang `flows` and `messages`\n",
    "- `factcheck.co` - A colang file demonstrating one way of implementing a Fact Checking rail using the `check_facts` action\n",
    "- `hallucination.co` - A colang file demonstrating one way of implementing a hallucination detection rail using the `check_hallucination` action\n",
    "\n",
    "\n",
    "## Building the bot\n",
    "\n",
    "To explore some of the capabilities, we'll ask questions about the document in our [knowledge base](./kb/) folder, which is the jobs report for march 2023. We'll see how we can use a large language model to answer questions about this document, and how we can use guardrails to control the outputs of the model to make sure they are factual.\n",
    "\n",
    "To start off with, we'll define some settings for our LLM and conversational flow. In the first file, `llm_config.yaml`, we'll specify that we want to use OpenAI's davinci model as the underlying engine of our chatbot.\n",
    "\n",
    "```yaml\n",
    "models:\n",
    "  - type: main\n",
    "    engine: openai\n",
    "    model: text-davinci-003\n",
    "```\n",
    "\n",
    "We'll also create a very simple outline of the kind of conversations we'd like to enable. For this example, we want to focus on the report in our knowledge base -- so we'll just create one flow. We give some examples of the user `ask about report` intent, and tell the bot that when the user asks about the report, we want it to provide an answer from the report.\n",
    "\n",
    "If you already have `factcheck.co` file in your directory, delete it and replace it with the below:\n",
    "\n",
    "```colang\n",
    "define user ask about report\n",
    "  \"What was last month's unemployment rate?\"\n",
    "  \"Which industry added the most jobs?\"\n",
    "  \"How many people are currently unemployed?\"\n",
    "\n",
    "define flow answer report question\n",
    "  user ask about report\n",
    "  bot provide report answer\n",
    "```\n",
    "\n",
    "We've also added some more generic flows to `general.co` to round out the bot's capabilities and give it some examples of how to respond to user queries.\n",
    "\n",
    "Throughout this example, we'll be interacting with our bot through the python API. Feel free to follow along in a terminal or notebook. You can also use the `nemoguardrails` command line tool to launch an interactive terminal or web chat interface.\n",
    "\n",
    "To use the python API, we'll start by importing the `nemoguardrails` library, and make sure our OpenAI API key is available in the environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cacbf910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemoguardrails.rails import LLMRails, RailsConfig\n",
    "import os\n",
    "import getpass\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    api_key = getpass.getpass(\"Enter OpenAI API key:\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6fe6a2",
   "metadata": {},
   "source": [
    "After writing our config file and defining our flow, we're ready to initialize our chatbot. Using `RailsConfig.from_path` also ensures that our chatbot will have access to the files in the `kb` knowledge base folder. Feel free to set `verbose` to `True` here if you'd like to see more details about how our chatbot communicates with the large language model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46040918",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RailsConfig.from_path(\".\")\n",
    "app = LLMRails(config, verbose=True)  # Set verbose to True to see more details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de7866",
   "metadata": {},
   "source": [
    "We're ready to start chatting. We'll add our first user utterance to the chat log, and let the chatbot generate a message. We'll start with a pretty easy question about the top-line unemployment rate, a question which exactly matches one of our previously defined `ask about report` queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dffc221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the March 2023 US jobs report, the unemployment rate changed little at 3.5 percent.\n"
     ]
    }
   ],
   "source": [
    "history = [{\"role\": \"user\", \"content\": \"What was last month's unemployment rate?\"}]\n",
    "bot_message = await app.generate_async(messages=history)\n",
    "print(bot_message['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3704e4",
   "metadata": {},
   "source": [
    "Sure enough, the model has no issue producing an accurate response. Let's append that message to our chat log and ask something _slightly_ more difficult that doesn't appear in our intent configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa18ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the March 2023 US jobs report, the unemployment rate for teenagers was 9.8%.\n"
     ]
    }
   ],
   "source": [
    "history.append(bot_message)\n",
    "history.append(\n",
    "    {\"role\": \"user\", \"content\": \"What was the unemployment rate for teenagers?\"}\n",
    ")\n",
    "bot_message = await app.generate_async(messages=history)\n",
    "print(bot_message['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fc4542",
   "metadata": {},
   "source": [
    "No problem here either. Let's give it one more for good measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42ba6e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the March 2023 US jobs report, the unemployment rate for senior citizens was 7.2%.\n",
      "The previous answer is prone to hallucination and may not be accurate. Please double check the answer using additional sources.\n"
     ]
    }
   ],
   "source": [
    "history.append(bot_message)\n",
    "history.append(\n",
    "    {\"role\": \"user\", \"content\": \"What was the unemployment rate for senior citizens?\"}\n",
    ")\n",
    "bot_message = await app.generate_async(messages=history)\n",
    "print(bot_message['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9323b0b9",
   "metadata": {},
   "source": [
    "That certainly sounds reasonable, but there's a problem! If you look over the report carefully, you'll notice that it doesn't include any information about the unemployment rate for senior citizens -- and the training data for the language model does not include information from 2023. This is an issue known as hallucination, where a language model responds confidently to a query with information that is unsupported."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199511c8",
   "metadata": {},
   "source": [
    "## Fact Checking Rail\n",
    "\n",
    "The fact checking rail enables you to check the validity of the bot response based on the knowledge base. It takes as inputs the bot response and the relevant chunk from the knowledge base, and makes a call to the LLM asking if the response is true based on the retrieved chunk. The actual format of the LLM call can be seen in [`actions/fact_checking.py`](../../nemoguardrails/actions/fact_checking.py).\n",
    "\n",
    "Let's modify our flow from before to add the fact checking rail. Now, when the bot provides its answer, we'll execute the `check_facts` action, and store the response in the `accurate` variable. If the fact checking action deems the response to be false, we'll remove that message from the response and let the user know that the bot doesn't know the answer.\n",
    "\n",
    "We also need to include a way to actually delete a message. NeMo Guardrails includes a special case, where the bot responding with the literal phrase `(remove last message)` causes the most recent message to be removed from the response. So we can include that exact response in our flow.\n",
    "\n",
    "```colang\n",
    "define user ask about report\n",
    "  \"What was last month's unemployment rate?\"\n",
    "  \"Which industry added the most jobs?\"\n",
    "  \"How many jobs were added in the transportation industry?\"\n",
    "\n",
    "define flow answer report question\n",
    "  user ask about report\n",
    "  bot provide report answer\n",
    "  $accurate = execute check_facts\n",
    "  if not $accurate\n",
    "    bot remove last message\n",
    "    bot inform answer unknown\n",
    "\n",
    "define bot remove last message\n",
    "  \"(remove last message)\"\n",
    "```\n",
    "\n",
    "With our flow modified, we'll need to reinitialize our chatbot. This time, let's set `verbose=True` so we can see what's going on more closely. The full output is pretty long, so we'll condense it down to the most relevant bits in this document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c1375aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RailsConfig.from_path(\".\")\n",
    "app = LLMRails(config, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c605cb",
   "metadata": {},
   "source": [
    "Now let's ask the previous question again. Since it's already at the bottom of our chat log, we can just pass the existing chat log directly into the new chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1028824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mI'm sorry, I don't know the answer to that. However, I can look up the information for you. Would that be helpful?\n",
      "The above response may have been hallucinated, and should be independently verified.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "bot_message = await app.generate_async(messages=history)\n",
    "print(f\"\\033[92m{bot_message['content']}\\033[0m\")\n",
    "history.append(bot_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b41243a",
   "metadata": {},
   "source": [
    "Everything up until `Finished chain.` is part of the bot's \"internal reasoning\", with the text afterward actually being returned as the response. If you take a look at the output log above, you'll see that the LLM model still initially responds with the same false answer as before. But then it kicks off the `check_facts` action, and we see that the result was False. So, just as we defined, the bot removes the last, incorrect message and generates a response that corresponds to the `inform answer unknown` intent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fa10d3",
   "metadata": {},
   "source": [
    "## Hallucination Rail\n",
    "\n",
    "While the fact checking action works well when we have a relevant knowledge base to check against, we'd also like to guard against hallucination when we don't have a pre-configured knowledge base. For this use case, we can use the [`check_hallucination`](../../nemoguardrails/actions/hallucination/hallucination.py) action.\n",
    "\n",
    "The hallucination rail uses a self-checking mechanism inspired by the [SelfCheckGPT](https://arxiv.org/abs/2303.08896) technique. Similar to the fact-checking rail, we ask the LLM itself to determine whether the most recent output is consistent with a piece of context. However, since we don't have a knowledge base to pull the context from, we use the LLM to generate multiple additional completions to serve as the context. The assumption is that if the LLM produces multiple completions that are inconsistent with each other, the original completion is likely to be a hallucination.\n",
    "\n",
    "You can view [`actions/hallucination/hallucination.py`](../../nemoguardrails/actions/hallucination/hallucination.py) to see the format of the the extra generations and the hallucination check call.\n",
    "\n",
    "The current implementation only supports OpenAI LLM Engines.\n",
    "\n",
    "Let's add a flow into `hallucination.co` to check for hallucination in our bot's responses. Unlike before, we want to check for hallucination on all responses, so we'll use the `bot ...` command in our flow definition. The `...` token indicates a wildcard, and will match on any bot response. Also unlike the fact checking bot, instead of removing the bot response when hallucination is detected, we'll have the bot generate a warning the user that the answer may be hallucinated based on a couple of examples.\n",
    "\n",
    "```colang\n",
    "define flow check hallucination\n",
    "    bot ...\n",
    "    $result = execute check_hallucination\n",
    "    if $result\n",
    "        bot inform answer prone to hallucination\n",
    "\n",
    "define bot inform answer prone to hallucination\n",
    "    \"The previous answer is prone to hallucination and may not be accurate. Please double check the answer using additional sources.\"\n",
    "    \"The above response may have been hallucinated, and should be independently verified.\"\n",
    "```\n",
    "\n",
    "With our flow defined, we'll ask our bot a question that's totally unrelated to the information in its knowledge base. While LLMs can hallucinate responses for many kinds of prompts, they are especially prone to doing so when asking for specific information, like when asking about person, asking for medical advice, or asking quantitative questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f85c90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The NVIDIA GeForce RTX 4090 has 10752 CUDA cores. Is there anything else I can help you with?\n",
      "The above response may have been hallucinated, and should be independently verified.\n"
     ]
    }
   ],
   "source": [
    "config = RailsConfig.from_path(\".\")\n",
    "app = LLMRails(config, verbose=True)\n",
    "history = [{\"role\": \"user\", \"content\": \"How many CUDA cores does a 4090 have?\"}]\n",
    "bot_message = await app.generate_async(messages=history)\n",
    "print(bot_message['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3603a8a",
   "metadata": {},
   "source": [
    "### UI\n",
    "\n",
    "Guardrails allows users to interact with the server with a stock UI. To launch the\n",
    "server and access the UI to interact with this example, the following steps are\n",
    "recommended:\n",
    "\n",
    "* Launch the server with the command: `nemoguardrails server`\n",
    "* Once the server is launched, you can go to: `http://localhost:8000` to access\n",
    "the UI\n",
    "* Click \"New Chat\" on the top left corner of the screen and then proceed to\n",
    "pick `grounding_rail` from the drop-down menu.\n",
    "\n",
    "Refer [Guardrails Server Documentation](../../docs/user_guide/interface-guide.md#guardrails-server) for more information.\n",
    "\n",
    "### Command Line Chat\n",
    "\n",
    "To chat with the bot with a command line interface simply use the following\n",
    "command while you are in this folder:\n",
    "\n",
    "```bash\n",
    "nemoguardrails chat --config=.\n",
    "```\n",
    "Refer [Guardrails CLI Documentation](../../docs/user_guide/interface-guide.md#guardrails-cli) for more information.\n",
    "\n",
    "* [Explore more examples](../README.md#examples) to help steer your bot!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
